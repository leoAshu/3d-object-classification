{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5fbe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "# utility\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from path import Path\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# plots\n",
    "import scipy.spatial.distance\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ec87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41bafe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'bathtub': 1,\n",
       " 'bed': 2,\n",
       " 'bench': 3,\n",
       " 'bookshelf': 4,\n",
       " 'bottle': 5,\n",
       " 'bowl': 6,\n",
       " 'car': 7,\n",
       " 'chair': 8,\n",
       " 'cone': 9,\n",
       " 'cup': 10,\n",
       " 'curtain': 11,\n",
       " 'desk': 12,\n",
       " 'door': 13,\n",
       " 'dresser': 14,\n",
       " 'flower_pot': 15,\n",
       " 'glass_box': 16,\n",
       " 'guitar': 17,\n",
       " 'keyboard': 18,\n",
       " 'lamp': 19,\n",
       " 'laptop': 20,\n",
       " 'mantel': 21,\n",
       " 'monitor': 22,\n",
       " 'night_stand': 23,\n",
       " 'person': 24,\n",
       " 'piano': 25,\n",
       " 'plant': 26,\n",
       " 'radio': 27,\n",
       " 'range_hood': 28,\n",
       " 'sink': 29,\n",
       " 'sofa': 30,\n",
       " 'stairs': 31,\n",
       " 'stool': 32,\n",
       " 'table': 33,\n",
       " 'tent': 34,\n",
       " 'toilet': 35,\n",
       " 'tv_stand': 36,\n",
       " 'vase': 37,\n",
       " 'wardrobe': 38,\n",
       " 'xbox': 39}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define data folder path\n",
    "data_path = Path('./data/model-net-40')\n",
    "\n",
    "# extract all folder names\n",
    "folders = [dir for dir in sorted(os.listdir(data_path)) if os.path.isdir(data_path/dir)]\n",
    "\n",
    "# extract class names from the list of folder names\n",
    "classes = {folder: i for i, folder in enumerate(folders)}\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70cb694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "# reads an OFF file\n",
    "# returns the list of vertices and faces\n",
    "def read_off(file):\n",
    "    # reads the first line\n",
    "    off_header = file.readline().strip()\n",
    "    \n",
    "    # checks if the first line is OFF\n",
    "    if 'OFF' == off_header:\n",
    "        # first line is OFF\n",
    "        # reads second line to extract #vertices and #faces\n",
    "        n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split()])\n",
    "    else:\n",
    "        # first line is not OFF\n",
    "        # extracts #vertices and #faces from first line\n",
    "        n_verts, n_faces, __ = tuple([int(s) for s in off_header[3:].split()])\n",
    "       \n",
    "    # reads and extracts the list of vertices\n",
    "    verts = []\n",
    "    for v_idx in range(n_verts):\n",
    "        x, y, z = map(float, file.readline().strip().split())\n",
    "        verts.append((x, y, z))\n",
    "    \n",
    "    # reads and extracts the list of faces\n",
    "    # discards the first value of each face (#vertices)\n",
    "    # assumption: each face is described using 3 vertices\n",
    "    faces = []\n",
    "    for f_idx in range(n_faces):\n",
    "        face = [int(v_idx) for v_idx in file.readline().strip().split()[1:]]\n",
    "        faces.append(face)\n",
    "    \n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba7ecf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility class to sample specific number of points within an object's area\n",
    "class PointSampler(object):\n",
    "    # constructor\n",
    "    # output_size: number of points to be sampled\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    \n",
    "    # calculates area of a triangle\n",
    "    # requires 3 points as the triangle vertices\n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        a = np.linalg.norm(pt1 - pt2)\n",
    "        b = np.linalg.norm(pt2 - pt3)\n",
    "        c = np.linalg.norm(pt3 - pt1)\n",
    "        s = (a + b + c) / 2\n",
    "        \n",
    "        return math.sqrt(max(s * (s-a) * (s-b) * (s-c), 0))\n",
    "    \n",
    "    \n",
    "    # samples a point using barycentric coordinates\n",
    "    # the points lie inside the triangle\n",
    "    # requires 3 points as the triangle vertices\n",
    "    def sample_point(self, pt1, pt2, pt3):\n",
    "        # barycentric coordinates on a triangle\n",
    "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
    "        \n",
    "        s, t = sorted([random.random(), random.random()])\n",
    "        f = lambda i: s * pt1[i] + (t-s) * pt2[i] + (1-t) * pt3[i]\n",
    "        \n",
    "        return (f(0), f(1), f(2))\n",
    "    \n",
    "    \n",
    "    # calls the object functions internally to sample points\n",
    "    def __call__(self, mesh):\n",
    "        verts, faces = mesh\n",
    "        verts = np.array(verts)\n",
    "        areas = np.zeros(len(faces))\n",
    "        \n",
    "        # calculate the area of each face\n",
    "        for i in range(len(areas)):\n",
    "            areas[i] = self.triangle_area(\n",
    "                verts[faces[i][0]],\n",
    "                verts[faces[i][1]],\n",
    "                verts[faces[i][2]]\n",
    "            )\n",
    "            \n",
    "        # samples the required number of faces\n",
    "        sampled_faces = random.choices(faces, weights=areas, cum_weights=None, k=self.output_size)\n",
    "        \n",
    "        # creates an empty list of points\n",
    "        # size of the list is equal to the required number of sampled points\n",
    "        sampled_points = np.zeros((self.output_size, 3))\n",
    "        \n",
    "        # samples the points using the randomly sampled faces\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i] = (self.sample_point(\n",
    "                verts[sampled_faces[i][0]],\n",
    "                verts[sampled_faces[i][1]],\n",
    "                verts[sampled_faces[i][2]]\n",
    "            ))\n",
    "        \n",
    "        return sampled_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51e7ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility class to normalize a pointcloud data\n",
    "# the normalized coordinates fall in the range [-1, 1]\n",
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape) == 2\n",
    "        \n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)\n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "        \n",
    "        return norm_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c8b14add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility class to rotate pointcloud coordinates along z-axis by a random angle\n",
    "class RandRotation_z(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape) == 2\n",
    "        \n",
    "        # calculate a random theta (angle of rotation)\n",
    "        theta = random.random() * 2 * math.pi\n",
    "        \n",
    "        # generate a rotation matrix\n",
    "        rot_matrix = np.array([\n",
    "            [math.cos(theta), -math.sin(theta), 0],\n",
    "            [math.sin(theta), math.cos(theta), 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        \n",
    "        # rotate the pointcloud data\n",
    "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "        \n",
    "        return rot_pointcloud\n",
    "    \n",
    "\n",
    "# utility class to add random noise to pointcloud data\n",
    "# noise range: [0, 0.02]\n",
    "class RandomNoise(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape) == 2\n",
    "        \n",
    "        # generate a noise array of same shape as pointcloud data\n",
    "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "        \n",
    "        # add noise to the pointcloud data\n",
    "        noisy_pointcloud = pointcloud + noise\n",
    "        \n",
    "        return noisy_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ccf0d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility class to convert pointcloud data from numpy array into a pytorch tensor\n",
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape) == 2\n",
    "        \n",
    "        return torch.from_numpy(pointcloud)\n",
    "    \n",
    "\n",
    "# utility function\n",
    "# combines all types of pointcloud transform functions\n",
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "        PointSampler(1024),\n",
    "        Normalize(),\n",
    "        ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dbe35b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder='train', transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform if not valid else default_transforms()\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):\n",
    "                    sample = {}\n",
    "                    sample['pcd_path'] = new_dir/file\n",
    "                    sample['category'] = category\n",
    "                    self.files.append(sample)\n",
    "                    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __preproc__(self, file):\n",
    "        verts, faces = read_off(file)\n",
    "        if self.transforms:\n",
    "            pointcloud = self.transforms((verts, faces))\n",
    "        return pointcloud\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud = self.__preproc__(f)\n",
    "        return {'pointcloud': pointcloud, 'category': self.classes[category]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b2c4b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    PointSampler(1024),\n",
    "    Normalize(),\n",
    "    RandRotation_z(),\n",
    "    RandomNoise(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3beb0d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PointCloudData(data_path, transform=train_transforms)\n",
    "valid_ds = PointCloudData(data_path, valid=True, folder='test', transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ea471474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'airplane',\n",
       " 1: 'bathtub',\n",
       " 2: 'bed',\n",
       " 3: 'bench',\n",
       " 4: 'bookshelf',\n",
       " 5: 'bottle',\n",
       " 6: 'bowl',\n",
       " 7: 'car',\n",
       " 8: 'chair',\n",
       " 9: 'cone',\n",
       " 10: 'cup',\n",
       " 11: 'curtain',\n",
       " 12: 'desk',\n",
       " 13: 'door',\n",
       " 14: 'dresser',\n",
       " 15: 'flower_pot',\n",
       " 16: 'glass_box',\n",
       " 17: 'guitar',\n",
       " 18: 'keyboard',\n",
       " 19: 'lamp',\n",
       " 20: 'laptop',\n",
       " 21: 'mantel',\n",
       " 22: 'monitor',\n",
       " 23: 'night_stand',\n",
       " 24: 'person',\n",
       " 25: 'piano',\n",
       " 26: 'plant',\n",
       " 27: 'radio',\n",
       " 28: 'range_hood',\n",
       " 29: 'sink',\n",
       " 30: 'sofa',\n",
       " 31: 'stairs',\n",
       " 32: 'stool',\n",
       " 33: 'table',\n",
       " 34: 'tent',\n",
       " 35: 'toilet',\n",
       " 36: 'tv_stand',\n",
       " 37: 'vase',\n",
       " 38: 'wardrobe',\n",
       " 39: 'xbox'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_classes = {i: category for category, i in train_ds.classes.items()}\n",
    "inv_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6c47dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  9843\n",
      "Valid dataset size:  2468\n",
      "Number of classes:  40\n",
      "Sample pointcloud shape:  torch.Size([1024, 3])\n",
      "Class:  airplane\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "print('Number of classes: ', len(train_ds.classes))\n",
    "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())\n",
    "print('Class: ', inv_classes[train_ds[0]['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1fea0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6b275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a417d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9739db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a93f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c05c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/balraj98/pointnet-for-3d-object-classification-ii-pytorch/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "db069811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.k=k\n",
    "        self.conv1 = nn.Conv1d(k,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape == (bs,n,3)\n",
    "        bs = input.size(0)\n",
    "        xb = F.relu(self.bn1(self.conv1(input)))\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "        pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        flat = nn.Flatten(1)(pool)\n",
    "        xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "        xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "\n",
    "        #initialize as identity\n",
    "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "        if xb.is_cuda:\n",
    "            init=init.cuda()\n",
    "        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "        return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "    def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 40):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e490a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id64x64=id64x64.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "de7c2d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "11bea280",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNet()\n",
    "pointnet.to(device);\n",
    "\n",
    "# Load a pre-trained model if it exists\n",
    "if os.path.exists('../model/pointnet-for-3d-object-classification-ii-pytorch/save.pth'):\n",
    "    pointnet.load_state_dict(torch.load('../model/pointnet-for-3d-object-classification-ii-pytorch/save.pth'))\n",
    "    print('Loaded Pre-trained PointNet Model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fd669cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5f616ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None,  epochs=1):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 5 == 4:    # print every 5 mini-batches\n",
    "                print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, len(train_loader), running_loss / 5))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100. * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "        # save the model\n",
    "        torch.save(pointnet.state_dict(), \"save.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1505c14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Batch:    5 /  308], loss: 3.681\n",
      "[Epoch: 1, Batch:   10 /  308], loss: 3.316\n",
      "[Epoch: 1, Batch:   15 /  308], loss: 3.256\n",
      "[Epoch: 1, Batch:   20 /  308], loss: 3.083\n",
      "[Epoch: 1, Batch:   25 /  308], loss: 2.814\n",
      "[Epoch: 1, Batch:   30 /  308], loss: 2.994\n",
      "[Epoch: 1, Batch:   35 /  308], loss: 2.840\n",
      "[Epoch: 1, Batch:   40 /  308], loss: 2.742\n",
      "[Epoch: 1, Batch:   45 /  308], loss: 2.831\n",
      "[Epoch: 1, Batch:   50 /  308], loss: 2.734\n",
      "[Epoch: 1, Batch:   55 /  308], loss: 2.779\n",
      "[Epoch: 1, Batch:   60 /  308], loss: 2.587\n",
      "[Epoch: 1, Batch:   65 /  308], loss: 2.642\n",
      "[Epoch: 1, Batch:   70 /  308], loss: 2.718\n",
      "[Epoch: 1, Batch:   75 /  308], loss: 2.541\n",
      "[Epoch: 1, Batch:   80 /  308], loss: 2.431\n",
      "[Epoch: 1, Batch:   85 /  308], loss: 2.404\n",
      "[Epoch: 1, Batch:   90 /  308], loss: 2.274\n",
      "[Epoch: 1, Batch:   95 /  308], loss: 2.255\n",
      "[Epoch: 1, Batch:  100 /  308], loss: 2.362\n",
      "[Epoch: 1, Batch:  105 /  308], loss: 2.461\n",
      "[Epoch: 1, Batch:  110 /  308], loss: 2.265\n",
      "[Epoch: 1, Batch:  115 /  308], loss: 2.599\n",
      "[Epoch: 1, Batch:  120 /  308], loss: 2.163\n",
      "[Epoch: 1, Batch:  125 /  308], loss: 2.407\n",
      "[Epoch: 1, Batch:  130 /  308], loss: 2.312\n",
      "[Epoch: 1, Batch:  135 /  308], loss: 2.419\n",
      "[Epoch: 1, Batch:  140 /  308], loss: 2.391\n",
      "[Epoch: 1, Batch:  145 /  308], loss: 2.184\n",
      "[Epoch: 1, Batch:  150 /  308], loss: 2.183\n",
      "[Epoch: 1, Batch:  155 /  308], loss: 2.421\n",
      "[Epoch: 1, Batch:  160 /  308], loss: 2.325\n",
      "[Epoch: 1, Batch:  165 /  308], loss: 2.318\n",
      "[Epoch: 1, Batch:  170 /  308], loss: 2.137\n",
      "[Epoch: 1, Batch:  175 /  308], loss: 2.233\n",
      "[Epoch: 1, Batch:  180 /  308], loss: 2.101\n",
      "[Epoch: 1, Batch:  185 /  308], loss: 2.002\n",
      "[Epoch: 1, Batch:  190 /  308], loss: 2.162\n",
      "[Epoch: 1, Batch:  195 /  308], loss: 2.348\n",
      "[Epoch: 1, Batch:  200 /  308], loss: 2.150\n",
      "[Epoch: 1, Batch:  205 /  308], loss: 2.179\n",
      "[Epoch: 1, Batch:  210 /  308], loss: 1.860\n",
      "[Epoch: 1, Batch:  215 /  308], loss: 2.133\n",
      "[Epoch: 1, Batch:  220 /  308], loss: 2.056\n",
      "[Epoch: 1, Batch:  225 /  308], loss: 2.002\n",
      "[Epoch: 1, Batch:  230 /  308], loss: 2.010\n",
      "[Epoch: 1, Batch:  235 /  308], loss: 2.001\n",
      "[Epoch: 1, Batch:  240 /  308], loss: 1.975\n",
      "[Epoch: 1, Batch:  245 /  308], loss: 2.126\n",
      "[Epoch: 1, Batch:  250 /  308], loss: 2.007\n",
      "[Epoch: 1, Batch:  255 /  308], loss: 1.811\n",
      "[Epoch: 1, Batch:  260 /  308], loss: 1.883\n",
      "[Epoch: 1, Batch:  265 /  308], loss: 1.909\n",
      "[Epoch: 1, Batch:  270 /  308], loss: 1.679\n",
      "[Epoch: 1, Batch:  275 /  308], loss: 2.107\n",
      "[Epoch: 1, Batch:  280 /  308], loss: 1.798\n",
      "[Epoch: 1, Batch:  285 /  308], loss: 1.896\n",
      "[Epoch: 1, Batch:  290 /  308], loss: 1.931\n",
      "[Epoch: 1, Batch:  295 /  308], loss: 1.898\n",
      "[Epoch: 1, Batch:  300 /  308], loss: 1.583\n",
      "[Epoch: 1, Batch:  305 /  308], loss: 1.720\n",
      "Valid accuracy: 40 %\n"
     ]
    }
   ],
   "source": [
    "train(pointnet, train_loader, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
